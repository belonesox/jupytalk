{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Revue de comp\u00e9titions Kaggle (2017)\n",
        "\n",
        "Les gagnants des comp\u00e9titions [Kaggle](https://www.kaggle.com/) d\u00e9crivent parfois leurs solutions sur le blog de Kaggle [No Free Hunch](http://blog.kaggle.com/). Il y a toujours de bonnes id\u00e9es \u00e0 glaner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le [blog Kaggle](http://blog.kaggle.com/) publie r\u00e9guli\u00e8rement des interviews des gagnants des comp\u00e9titions. C'est l'occasion de d\u00e9couvrir la meilleur solution et les outils qui ont permis de la mettre en place. Certains sujets sont des comp\u00e9titions acad\u00e9miques et les gagnants mettent parfois leur code \u00e0 disposition sous Github."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "## The Nature Conservancy Fisheries Monitoring\n",
        "\n",
        "[kaggle](https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring)\n",
        "\n",
        "* **Objectif :** classification d'images de poissons\n",
        "* **donn\u00e9es :** images de poisssons et l'esp\u00e8ces \u00e0 reconna\u00eetre\n",
        "\n",
        "[The Nature Conservancy Fisheries Monitoring Competition, 1st Place Winner's Interview: Team 'Towards Robust-Optimal Learning of Learning'](http://blog.kaggle.com/2017/07/07/the-nature-conservancy-fisheries-monitoring-competition-1st-place-winners-interview-team-towards-robust-optimal-learning-of-learning/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### El\u00e9ments cl\u00e9s de la solution\n",
        "\n",
        "* La solution s'inspire de **transfer learning** : [VGG-16](https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3), [ResNet-101](https://gist.github.com/flyyufelix/65018873f8cb2bbe95f429c474aa1294).\n",
        "* Un mod\u00e8le de **Fast-RNN** a \u00e9t\u00e9 utilis\u00e9e pour extraire les bo\u00eetes englobantes des poissons.\n",
        "* Les images \u00e9taient de **tailles diff\u00e9rentes**, grandes et petites. Plut\u00f4t que de les normaliser toutes \u00e0 la m\u00eame taille, **deux mod\u00e8les** pr\u00e9-entra\u00een\u00e9s sur des tailles diff\u00e9rentes ont \u00e9t\u00e9 mis en concurrence.\n",
        "* Les images ont \u00e9t\u00e9 r\u00e9annot\u00e9es avec des **bo\u00eetes englobantes polygonales**. Les poissons sur le pont d'un bateau sont diff\u00e9rentes des images de poissons habituelles. Il fallait faire attention \u00e0 ce que le mod\u00e8le de classification n'utilise pas le bateau comme features pour classer un type de poisson que ce bateau p\u00eache souvent.\n",
        "* La base d'images d'apprentissage a \u00e9t\u00e9 augment\u00e9e avec des op\u00e9rations classiques (**rotations, flous, ...**)\n",
        "* Il y avait des **images prises de nuits** mais sous-repr\u00e9sent\u00e9es. Une des t\u00e2ches \u00e0 consister \u00e0 cr\u00e9er plus d'images de nuits \u00e0 partir des images prises de jours en redressant les distributions des couleurs.\n",
        "* Carte NVIDIA : 2x NVIDIA GTX 1080, 1x NVIDIA TITAN X\n",
        "* Le meilleur mod\u00e8le a n\u00e9cessit\u00e9 4h d'apprentissage et n\u00e9cessitait 0.5 secondes pour la pr\u00e9diction.\n",
        "\n",
        "Sur GitHub : [amsqr/Allen_AI_Kaggle](https://github.com/amsqr/Allen_AI_Kaggle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Id\u00e9es \u00e0 r\u00e9cup\u00e9rer\n",
        "\n",
        "* Le bateau et l'esp\u00e8ce de poisson \u00e9taient corr\u00e9l\u00e9s. Il fallait r\u00e9duire cette corr\u00e9lation.\n",
        "* Certaines images \u00e9taient tr\u00e8s types (de nuit) et sous-repr\u00e9sent\u00e9es. Il a fallu redresser la base d'apprentissage de ces petits biais.\n",
        "* Transfer Learning en premi\u00e8re approche."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "## Data Science Bowl 2017: Can you improve lung cancer detection?\n",
        "\n",
        "[kaggle](https://www.kaggle.com/c/data-science-bowl-2017)\n",
        "\n",
        "* **objectif :** d\u00e9tecter la pr\u00e9sence d'un cancer du poumon\n",
        "* **donn\u00e9es :** scan 3D des poumons haute r\u00e9solution\n",
        "\n",
        "[2017 Data Science Bowl, Predicting Lung Cancer: 2nd Place Solution Write-up, Daniel Hammack and Julian de Wit](http://blog.kaggle.com/2017/06/29/2017-data-science-bowl-predicting-lung-cancer-2nd-place-solution-write-up-daniel-hammack-and-julian-de-wit/), [2nd place solution for the 2017 national datascience bowl](http://juliandewit.github.io/kaggle-ndsb2017/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### El\u00e9ments de solutions\n",
        "\n",
        "* Les gagnants ont **augment\u00e9s leurs donn\u00e9es** avec les r\u00e9sultats du challenge [Lung Nodule Andalysis 2016](https://luna16.grand-challenge.org/) (de cet article [Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: The LUNA16 challenge](http://www.medicalimageanalysisjournal.com/article/S1361-8415(17)30102-0/fulltext)), et des tutoriels [Full Preprocessing Tutorial](https://www.kaggle.com/gzuidhof/full-preprocessing-tutorial) ainsi que les [autres](https://www.kaggle.com/c/data-science-bowl-2017/kernels) comme celui-ci [Applying a 3D convolutional neural network to the data](https://www.kaggle.com/sentdex/first-pass-through-data-w-3d-convnet)\n",
        "* La premi\u00e8re \u00e9tape a \u00e9t\u00e9 de **reconstituer les images 3D** (une image 3D = s\u00e9quence d'images 2D prise \u00e0 intervalle r\u00e9gulier)\n",
        "* Le probl\u00e8mes **a \u00e9t\u00e9 modifi\u00e9** en pr\u00e9dictions de la taille des nodules (\u00e0 partir d'autres jeux de donn\u00e9es [LIDC](https://www.ncbi.nlm.nih.gov/pubmed/18035277)) sur des bouts de scans puis pr\u00e9diction de la probabilit\u00e9s de cancer.\n",
        "* Utilisation de la m\u00e9thode [Curriculum Learning](https://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf) qui consiste \u00e0 apprendre un mod\u00e8le **d'abord sur des donn\u00e9es propres** puis \u00e0 ajouter petit \u00e0 petit des exemples plus difficiles \u00e0 classer.\n",
        "* Pas d'utilisation de mod\u00e8les connus [U-net](https://arxiv.org/abs/1505.04597) (mod\u00e8les de deep learning sp\u00e9cialis\u00e9s dans la segmentation d'images m\u00e9dicales) mais utilisation de **CNN sur des fen\u00eatres glissantes**.\n",
        "* Le mod\u00e8le [C3D](http://vlg.cs.dartmouth.edu/c3d/) (**Convolution 3D**) n'a pas march\u00e9 tel quel mais le mod\u00e8le final est tr\u00e8s proche de la m\u00eame architecture ([github/C3D](https://github.com/facebook/C3D)).\n",
        "* Deux auteurs, deux codes : [code 1](https://github.com/juliandewit/kaggle_ndsb2017),\n",
        "[code 2](https://github.com/dhammack/DSB2017), [rapport](https://github.com/dhammack/DSB2017/blob/master/dsb_2017_daniel_hammack.pdf) et autres r\u00e9f\u00e9rences.\n",
        "* L'\u00e9quipe arriv\u00e9e 9\u00e8me a d\u00e9crit sa solution [Predicting lung cancer](https://eliasvansteenkiste.github.io/machine%20learning/lung-cancer-pred/) - un peu plus clair et didactique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Id\u00e9es \u00e0 r\u00e9cup\u00e9rer\n",
        "\n",
        "* Utilisation de mod\u00e8les existants pour pr\u00e9dire des r\u00e9sultats interm\u00e9diaires sur les nodules pour augmenter les donn\u00e9es.\n",
        "* Exemple de code avec des mod\u00e8les de convolution 3D.\n",
        "* Architecture gagnante : U-net](https://arxiv.org/abs/1505.04597), [C3D](http://vlg.cs.dartmouth.edu/c3d/)\n",
        "* Base de donn\u00e9es m\u00e9dicales : [Lung Nodule Andalysis 2016](https://luna16.grand-challenge.org/), [LIDC](https://www.ncbi.nlm.nih.gov/pubmed/18035277)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## March Machine Learning Mania 2017: Predict the 2017 NCAA Basketball Tournament\n",
        "\n",
        "[kaggle](https://www.kaggle.com/c/march-machine-learning-mania-2017)\n",
        "\n",
        "* **objectif :** pr\u00e9dire des r\u00e9sultats de basket-ball\n",
        "* **donn\u00e9es :** donn\u00e9es des matchs pass\u00e9s\n",
        "\n",
        "[March Machine Learning Mania, 5th Place Winner's Interview: David Scott](http://blog.kaggle.com/2017/05/23/march-machine-learning-mania-5th-place-winners-interview-david-scott/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Elements de solution\n",
        "\n",
        "* Le participant arriv\u00e9 5\u00e8me est un **passionn\u00e9 de basket et de r\u00e9gression logistique** et c'est tout ce qu'il avouera.\n",
        "* Le premier a r\u00e9utilis\u00e9 la solution d'ancien vainqueur [Building an NCAA mens basketball predictive model and quantifying its success](https://arxiv.org/abs/1412.0248).\n",
        "* Utilisation de [Linear Mixed Effects Models](http://www.statsmodels.org/dev/mixed_linear.html) qui s'appliquent sur des **donn\u00e9es non ind\u00e9pendantes** : utilisation d'une variable de groupe.\n",
        "* Le challenge \u00e9tait \u00e9valu\u00e9 avec la formule suivante : $LogLoss = -\\frac{1}{n} \\sum_{i=1}^{n} y_i \\log \\hat{y_i} + (1-y_i) \\log (1-\\hat{y_i})$ avec $\\hat{y_i}$ la probabilit\u00e9 pour l'\u00e9quipe 1 de battre l'\u00e9quipe 2. Ce type d'erreur marche plut\u00f4t bien pour la r\u00e9gression logistique puisqu'elle optimise cette erreur.\n",
        "* Le gagnant a construit **15 features** issues de la connaissance du basket (degr\u00e9 d'offensivit\u00e9...).\n",
        "* Il fallait aussi **pr\u00e9dire le gagnant d'un tournoi** : cette pr\u00e9diction a \u00e9t\u00e9 r\u00e9alis\u00e9e \u00e0 partir de simulation faite \u00e0 partir du mod\u00e8le appris."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Id\u00e9es \u00e0 r\u00e9cup\u00e9rer\n",
        "\n",
        "* Il vaut conna\u00eetre le basket."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dstl Satellite Imagery Feature Detection\n",
        "\n",
        "[kaggle](https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection)\n",
        "\n",
        "* **objectif :** reconna\u00eetre des objets (voitures, b\u00e2timents, routes, arbres, cours d'eau, lacs...) dans de grandes images satellites\n",
        "* **donn\u00e9es :** grandes images satellistes, la m\u00eame zone est recouverte avec diff\u00e9rents types de capteurs (noir et blanc, infra...)\n",
        "\n",
        "[Dstl Satellite Imagery Competition, 3rd Place Winners' Interview: Vladimir & Sergey](http://blog.kaggle.com/2017/05/09/dstl-satellite-imagery-competition-3rd-place-winners-interview-vladimir-sergey/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### El\u00e9ments de la solution\n",
        "\n",
        "* Pas d'utilisation de [Fast-RNN](https://arxiv.org/abs/1506.01497) ou [SSD](https://arxiv.org/abs/1512.02325) trop complexes \u00e0 mettre en oeuvre.\n",
        "* **Distributions des classes** : il y a plus d'arbres que de voitures, les pr\u00e9dictions doivent refl\u00e9ter cette distribution. Il est possible de modifier les pr\u00e9dictions afin de respecter cette distribution.\n",
        "* Utilisation des **d\u00e9tecteurs d'images simples** tels que [NDWI](https://en.wikipedia.org/wiki/Normalized_difference_water_index), cela marche assez bien pour les cours d'eau\n",
        "* Utilisation de **r\u00e9seaux de neurones** : [u-net](https://arxiv.org/abs/1505.04597), [Tiramisu](https://arxiv.org/abs/1611.09326), un optimiseur diff\u00e9rent [Incorporating Nesterov Momentum into Adam](http://cs229.stanford.edu/proj2015/054_report.pdf)\n",
        "* **Choisir les features** pour le r\u00e9seau de neurones : RBG, M, P images, on laisse tomber [ECI](https://en.wikipedia.org/wiki/Enhanced_vegetation_index), [SAVI](https://en.wikipedia.org/wiki/Soil-Adjusted_Vegetation_Index), [NDWI](https://en.wikipedia.org/wiki/Normalized_difference_water_index)\n",
        "* **D\u00e9couper les images** plut\u00f4t que les normaliser : un r\u00e9seau de neurones est appliqu\u00e9 sur chaque image. Probl\u00e8me : les pr\u00e9dictions sont moins bonnes sur les bords. On r\u00e9soud cela avec un quadrillage qui se superposent (**overlapping** grid) et on ajoute une couche dans le r\u00e9seau de neurones qui enl\u00e8ve les bords [Cropping2D](https://keras.io/layers/convolutional/#cropping2d).\n",
        "* Les images 3600x3600 ont \u00e9t\u00e9 d\u00e9coup\u00e9es en zones 112x112 : cela laisse des zones incompl\u00e8tes de l'autre c\u00f4t\u00e9 de l'image. Ces zones sont compl\u00e9t\u00e9es avec une image sym\u00e9trique (comme dans un miroir).\n",
        "* Pr\u00e9dire sur les images sym\u00e9triques et r\u00e9concilier les pr\u00e9dictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Id\u00e9es \u00e0 retenir\n",
        "\n",
        "* D\u00e9tecteurs d'images pour les arbres, les cours d'eau [ECI](https://en.wikipedia.org/wiki/Enhanced_vegetation_index), [SAVI](https://en.wikipedia.org/wiki/Soil-Adjusted_Vegetation_Index), [NDWI](https://en.wikipedia.org/wiki/Normalized_difference_water_index)\n",
        "* Corriger les sorties avec des informations sur une distribution a priori des objets \u00e0 d\u00e9tecter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autres comp\u00e9titions\n",
        "\n",
        "* [Two Sigma Financial Modeling Code Competition, 5th Place Winners' Interview: Team Best Fitting | Bestfitting, Zero, & CircleCircle](http://blog.kaggle.com/2017/05/11/two-sigma-financial-modeling-code-competition-5th-place-winners-interview-team-best-fitting-bestfitting-zero-circlecircle/) - algorithme de trading, la solution est assez classique et introduit des caract\u00e9ristiques que les mod\u00e8les ont du mal \u00e0 capturer comme des courtes p\u00e9riodes de fortes volatilit\u00e9s, des p\u00e9riodes assez calmes..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* [Santander Product Recommendation Competition: 3rd Place Winner's Interview, Ryuji Sakata](http://blog.kaggle.com/2017/02/22/santander-product-recommendation-competition-3rd-place-winners-interview-ryuji-sakata/) - recommandation de produits, ce participant a isol\u00e9 deux cat\u00e9gories de produits (tendances inhabituelles pour l'un des groupes) pour lesquels deux mod\u00e8les et deux jeux de features distincts ont \u00e9t\u00e9 construits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* [Seizure Prediction Competition, 3rd Place Winner's Interview: Gareth Jones](http://blog.kaggle.com/2017/01/10/seizure-prediction-competition-3rd-place-winners-interview-gareth-jones/) - pr\u00e9dire les crises (\u00e9pilepsie, ...). Les features s'appuient sur des \u00e9lectro-enc\u00e9phalogramme (EEG). A noter l'utlisation de [RUSboost](http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=9260A5C92AC5F8FA3B8590A53A06248D?doi=10.1.1.309.2305&rep=rep1&type=pdf) pour les probl\u00e8mes de donn\u00e9es mal balanc\u00e9es."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}